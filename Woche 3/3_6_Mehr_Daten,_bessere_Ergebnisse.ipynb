{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianwarmuth/openhpi-kipraxis/blob/main/Woche%203/3_6_Mehr_Daten%2C_bessere_Ergebnisse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fr1OlX9YZPt6",
      "metadata": {
        "id": "fr1OlX9YZPt6"
      },
      "source": [
        "## 0. Installieren aller Pakete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0uTRddOPZRrb",
      "metadata": {
        "id": "0uTRddOPZRrb"
      },
      "outputs": [],
      "source": [
        "# Hier die Kaggle Credentials einfügen (ohne Anführungszeichen)\n",
        "\n",
        "%env KAGGLE_USERNAME=openhpi\n",
        "%env KAGGLE_KEY=das_ist_der_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hRSgrairar7O",
      "metadata": {
        "id": "hRSgrairar7O"
      },
      "outputs": [],
      "source": [
        "!pip3 install skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac57d66",
      "metadata": {
        "id": "fac57d66"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from torch import nn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NIH4HySUawpl",
      "metadata": {
        "id": "NIH4HySUawpl"
      },
      "outputs": [],
      "source": [
        "class NeuralNetModule(nn.Module):\n",
        "    def __init__(self, num_inputs, num_units=20, nonlin=nn.ReLU()):\n",
        "        super(NeuralNetModule, self).__init__()\n",
        "\n",
        "        self.nonlin = nonlin\n",
        "        self.dense0 = nn.Linear(num_inputs, num_units)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.dense1 = nn.Linear(num_units, num_units)\n",
        "        self.output = nn.Linear(num_units, 2)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = self.nonlin(self.dense0(X))\n",
        "        X = self.dropout(X)\n",
        "        X = self.nonlin(self.dense1(X))\n",
        "        X = self.softmax(self.output(X))\n",
        "        return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b77c3599",
      "metadata": {
        "id": "b77c3599"
      },
      "outputs": [],
      "source": [
        "def evaluate_clf(test_X, labels, clf):\n",
        "    predictions = clf.predict(test_X)\n",
        "    report = classification_report(labels, predictions)\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb217d9",
      "metadata": {
        "id": "1eb217d9"
      },
      "source": [
        "## Download Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fc0b24",
      "metadata": {
        "id": "00fc0b24"
      },
      "source": [
        "### Manuell\n",
        "via https://www.kaggle.com/columbine/imdb-dataset-sentiment-analysis-in-csv-format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f172699",
      "metadata": {
        "id": "4f172699"
      },
      "source": [
        "### Via API\n",
        "\n",
        "Hinzufügen der kaggle.json\n",
        "Speichern als ~/.kaggle/kaggle.json auf Linux, OSX, oder andere UNIX-based Betriebssysteme und unter C:\\Users<Windows-username>.kaggle\\kaggle.json auf Windows\n",
        "\n",
        "Siehe https://www.kaggle.com/docs/api oder https://github.com/Kaggle/kaggle-api\n",
        "        \n",
        "Beispiel:\n",
        "~/kaggle/kaggle.json\n",
        "\n",
        "{\"username\":\"openHPI\",\"key\":\"das_ist_der_key\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1bef49c",
      "metadata": {
        "id": "c1bef49c"
      },
      "outputs": [],
      "source": [
        "!pip3 install kaggle\n",
        "!kaggle datasets download -d columbine/imdb-dataset-sentiment-analysis-in-csv-format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LQa1I8ZNftBH",
      "metadata": {
        "id": "LQa1I8ZNftBH"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"imdb-dataset-sentiment-analysis-in-csv-format.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "\n",
        "import os  \n",
        "os.rename('Train.csv','sentiment.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd78c83a",
      "metadata": {
        "id": "dd78c83a"
      },
      "outputs": [],
      "source": [
        "def read_and_parse_train_df(nrows):\n",
        "    df = pd.read_csv(\"sentiment.csv\", nrows=nrows)\n",
        "\n",
        "    # preprocessing\n",
        "    df[\"text\"] = df[\"text\"].apply(lambda x: x.lower())\n",
        "    df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\"\\'\", \"\"))\n",
        "    df[\"text\"] = df[\"text\"].apply(lambda x: BeautifulSoup(x).text)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def read_and_parse_test_df():\n",
        "    df = pd.read_csv(\"sentiment.csv\")\n",
        "    df = df.tail(1000)\n",
        "\n",
        "    # preprocessing\n",
        "    df[\"text\"] = df[\"text\"].apply(lambda x: x.lower())\n",
        "    df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\"\\'\", \"\"))\n",
        "    df[\"text\"] = df[\"text\"].apply(lambda x: BeautifulSoup(x).text)\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5f85c9",
      "metadata": {
        "id": "9d5f85c9"
      },
      "outputs": [],
      "source": [
        "test_df = read_and_parse_test_df()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705ef7b1",
      "metadata": {
        "id": "705ef7b1"
      },
      "source": [
        "# 3.6 Mehr Daten, bessere Ergebnisse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a72820d",
      "metadata": {
        "id": "3a72820d"
      },
      "outputs": [],
      "source": [
        "for nrows in [100, 500, 1_000, 5_000, 10_000, 49_000]:\n",
        "    print(f\"#{nrows}\")\n",
        "    print(\"-\" * 53)\n",
        "    train_df = read_and_parse_train_df(nrows)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    train_X = vectorizer.fit_transform(train_df[\"text\"]).astype(np.float32)\n",
        "    test_X = vectorizer.transform(test_df[\"text\"]).astype(np.float32)\n",
        "\n",
        "    neural_net = NeuralNetClassifier(\n",
        "        module=NeuralNetModule,\n",
        "        module__num_inputs = len(vectorizer.vocabulary_),\n",
        "        max_epochs=10,\n",
        "        optimizer=torch.optim.Adam,\n",
        "        iterator_train__shuffle=True,\n",
        "        verbose=0\n",
        "    )\n",
        "    neural_net.fit(train_X, train_df['label'])\n",
        "\n",
        "    evaluate_clf(test_X, test_df[\"label\"], neural_net)\n",
        "    print(\"\\n\"*2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "3.6 Mehr Daten, bessere Ergebnisse.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
