{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianwarmuth/openhpi-kipraxis/blob/main/Woche%203/3_5_Sentiment_Analyse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U6khWz8BZo94",
      "metadata": {
        "id": "U6khWz8BZo94"
      },
      "source": [
        "## 0. Installieren aller Pakete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-gx8OW-DZxyG",
      "metadata": {
        "id": "-gx8OW-DZxyG"
      },
      "outputs": [],
      "source": [
        "# Hier die Kaggle Credentials einfügen (ohne Anführungszeichen)\n",
        "\n",
        "%env KAGGLE_USERNAME=openhpi\n",
        "%env KAGGLE_KEY=das_ist_der_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32OHGQiQ_XoE",
      "metadata": {
        "id": "32OHGQiQ_XoE"
      },
      "outputs": [],
      "source": [
        "!pip install skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f552277",
      "metadata": {
        "id": "2f552277",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84d76a4",
      "metadata": {
        "id": "f84d76a4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ji0bDS__126",
      "metadata": {
        "id": "4ji0bDS__126"
      },
      "outputs": [],
      "source": [
        "class NeuralNetModule(nn.Module):\n",
        "    def __init__(self, num_inputs, num_units=20, nonlin=nn.ReLU()):\n",
        "        super(NeuralNetModule, self).__init__()\n",
        "\n",
        "        self.nonlin = nonlin\n",
        "        self.dense0 = nn.Linear(num_inputs, num_units)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.dense1 = nn.Linear(num_units, num_units)\n",
        "        self.output = nn.Linear(num_units, 2)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = self.nonlin(self.dense0(X))\n",
        "        X = self.dropout(X)\n",
        "        X = self.nonlin(self.dense1(X))\n",
        "        X = self.softmax(self.output(X))\n",
        "        return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11432047",
      "metadata": {
        "id": "11432047"
      },
      "source": [
        "# 3.5 Sentiment Analyse\n",
        "\n",
        "<img width=70% src=\"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/cover_sentiment.jpeg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45fa76b7",
      "metadata": {
        "id": "45fa76b7"
      },
      "source": [
        "### Was wir erreichen wollen\n",
        "\n",
        "In diesem Anwendungsfall wollen wir Filmbewertungen in positive und negative Bewertungen unterteilen. Dafür liegen uns eine Vielzahl gelabelter Trainingsdaten in englischer Sprache vor.\n",
        "\n",
        "Mit einem Modell wollen wir in der Lage sein, für neue Kommentare automatisiert die Stimmung analysieren zu können. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb217d9",
      "metadata": {
        "id": "1eb217d9"
      },
      "source": [
        "## Download Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fc0b24",
      "metadata": {
        "id": "00fc0b24"
      },
      "source": [
        "### Manuell\n",
        "via https://www.kaggle.com/columbine/imdb-dataset-sentiment-analysis-in-csv-format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f172699",
      "metadata": {
        "id": "4f172699"
      },
      "source": [
        "### Via API\n",
        "\n",
        "Hinzufügen der kaggle.json\n",
        "Speichern als ~/.kaggle/kaggle.json auf Linux, OSX, oder andere UNIX-based Betriebssysteme und unter C:\\Users<Windows-username>.kaggle\\kaggle.json auf Windows\n",
        "\n",
        "Siehe https://www.kaggle.com/docs/api oder https://github.com/Kaggle/kaggle-api\n",
        "        \n",
        "Beispiel:\n",
        "~/kaggle/kaggle.json\n",
        "\n",
        "{\"username\":\"openHPI\",\"key\":\"das_ist_der_key\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1bef49c",
      "metadata": {
        "id": "c1bef49c"
      },
      "outputs": [],
      "source": [
        "!pip3 install kaggle\n",
        "!kaggle datasets download -d columbine/imdb-dataset-sentiment-analysis-in-csv-format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LQa1I8ZNftBH",
      "metadata": {
        "id": "LQa1I8ZNftBH"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"imdb-dataset-sentiment-analysis-in-csv-format.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "\n",
        "import os  \n",
        "os.rename('Train.csv','sentiment.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-6KHbgZae5kK",
      "metadata": {
        "id": "-6KHbgZae5kK"
      },
      "outputs": [],
      "source": [
        "FILE_PATH = \"sentiment.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31336e0",
      "metadata": {
        "id": "f31336e0"
      },
      "source": [
        "### Daten vorbereiten\n",
        "\n",
        "Wir können nun unsere Daten laden und mit der Vorbereitung beginnen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45fd6bda",
      "metadata": {
        "id": "45fd6bda"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(FILE_PATH, nrows=10_000)\n",
        "df.head() # label 1 == positive; label 0 == negative"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40528912",
      "metadata": {
        "id": "40528912"
      },
      "source": [
        "Schauen wir uns zunächst einmal die Datenverteilung unserer Zielvariable an. Die Zielvariable ist kategorisch in diesem Fall:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c24ca5",
      "metadata": {
        "id": "38c24ca5"
      },
      "outputs": [],
      "source": [
        "df[\"label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf90b1da",
      "metadata": {
        "id": "bf90b1da"
      },
      "source": [
        "Wir sehen: unsere Daten sind nahezu perfekt gleichverteilt (50% positiv, 50% negativ). Das ist prinzipiell eine gute Nachricht für unser Trainingsvorhaben (je unbalancierter Daten sind, desto komplexer wird das Training i.d.R.).\n",
        "\n",
        "Werfen wir einen Blick auf das erste Beispiel, um ein Gefühl für die Datenbeschaffenheit zu erlangen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d93113",
      "metadata": {
        "id": "e6d93113"
      },
      "outputs": [],
      "source": [
        "df[\"text\"].iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25105a0f",
      "metadata": {
        "id": "25105a0f"
      },
      "source": [
        "Wir stellen fest:\n",
        "- Eine einzelne Bewertung kann recht lange sein. Das bedeutet für uns, dass Beispiele sowohl mehr Informationen, aber auch mehr \"Rauschen\" (für uns unwichtige Informationen) beinhalten können.\n",
        "- Es handelt sich um Webdaten, da HTML-Tags gesetzt sind. Wir sollten diese korrekt verarbeiten.\n",
        "- 's werden mit \\\\'s kodiert (was wiederum auf den Rohtext zurückzuführen ist)\n",
        "- Wir sollten die Wörter im Text zu Kleinbuchstaben konvertieren, um die Anzahl möglicher Wort-Variationen zu reduzieren. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d08245",
      "metadata": {
        "id": "b2d08245"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: x.lower())\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\"\\'\", \"\"))\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: BeautifulSoup(x).text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc3591a",
      "metadata": {
        "id": "5dc3591a"
      },
      "source": [
        "Schauen wir uns die gleiche Bewertung erneut an:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c500eeb",
      "metadata": {
        "id": "3c500eeb"
      },
      "outputs": [],
      "source": [
        "df[\"text\"].iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b69ad790",
      "metadata": {
        "id": "b69ad790"
      },
      "source": [
        "Das sieht schon deutlich besser aus. Fangen wir nun an, unsere Daten zu splitten. Wir nutzen hier der Einfachheit halber einen ganz simplen Split mit Standardeinstellungen (wir könnten auch andere Verfahren einsetzen).\n",
        "\n",
        "Wir teilen unsere Daten dabei in Trainings-, Validierungs- und Testsplit. Mit dem ersten trainieren wir die Modelle, mit dem zweiten suchen wir unser bestes Modell heraus, mit dem letzten validieren wir die Ergebnisse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b57cae",
      "metadata": {
        "id": "26b57cae"
      },
      "outputs": [],
      "source": [
        "train_df, test_valid_df = train_test_split(df)\n",
        "test_df, valid_df = train_test_split(test_valid_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7bc07aa",
      "metadata": {
        "id": "b7bc07aa"
      },
      "source": [
        "Bevor wir unsere KI-Pipeline bauen, schauen wir uns die Daten erneut an. Sicherheitshalber duplizieren wir unseren Trainingsdatensatz dafür. Wir schauen uns zunächst die Textlängen an:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f2036a1",
      "metadata": {
        "id": "4f2036a1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "analysis_df = train_df.copy()\n",
        "analysis_df[\"text_length\"] = analysis_df[\"text\"].apply(len)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "933b68e7",
      "metadata": {
        "id": "933b68e7"
      },
      "source": [
        "Nun können wir uns die Verteilungen einfach je Klasse (\"positiv\" und \"negativ\") visualisieren lassen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "777a46cb",
      "metadata": {
        "id": "777a46cb"
      },
      "outputs": [],
      "source": [
        "sns.histplot(data=analysis_df, x=\"text_length\", hue=\"label\", element=\"step\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e074e22",
      "metadata": {
        "id": "7e074e22"
      },
      "source": [
        "Wir erkennen keinen großen Unterschied zwischen den beiden Klassen in der Textlänge (d.h. sowohl positive als auch negative Bewertungen können sehr ausführlich sein).\n",
        "\n",
        "Schauen wir uns den Textkorpus nochmal genauer an:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69d92d32",
      "metadata": {
        "id": "69d92d32"
      },
      "outputs": [],
      "source": [
        "text_corpus = \" \".join(analysis_df[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab6bd8b",
      "metadata": {
        "id": "2ab6bd8b"
      },
      "source": [
        "Bauen wir uns nun eine Hilfsfunktion, mit der wir uns einfach die *n* häufigsten Wörter des Korpus anschauen können. Als Korpus bezeichnet man eine Sammlung von Texten. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d0b1109",
      "metadata": {
        "id": "9d0b1109"
      },
      "outputs": [],
      "source": [
        "def plot_most_common_words(text_corpus, n):\n",
        "    counter = Counter(text_corpus.split())\n",
        "    rank, words, occurences = [], [], []\n",
        "    for idx, (word, occurence) in enumerate(counter.most_common(n=n)):\n",
        "        rank.append(idx)\n",
        "        words.append(word)\n",
        "        occurences.append(occurence)\n",
        "        \n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(rank, occurences, s=0.01)\n",
        "    for idx, word in enumerate(words):\n",
        "        ax.annotate(word, (rank[idx], occurences[idx]))\n",
        "    plt.title(\"Zipf's law\")\n",
        "    plt.ylabel(\"Occurences\")\n",
        "    plt.xlabel(\"Rank\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7d0d1f",
      "metadata": {
        "id": "7e7d0d1f"
      },
      "source": [
        "Wir können nun in der Verteilung das sogenannte Zipf's Law erkennen: Jedes Wort tritt ungefähr invers proportional zu seinem Rang auf, d.h. das häufigste Wort doppelt so häufig wie das zweithäufigste. Solche Füllwörter machen einen Großteil unserer Daten aus. Das ist ein ganz bekanntes Phönomen in natürlichen Sprachen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db25aa27",
      "metadata": {
        "id": "db25aa27"
      },
      "outputs": [],
      "source": [
        "plot_most_common_words(text_corpus, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f788be9",
      "metadata": {
        "id": "1f788be9"
      },
      "source": [
        "Wir können diese Wörter entfernen, da sie inhaltlich keinen Mehrwert bringen. Als ersten Schritt erstellen wir ein Embedding für einzelne Wörter. Schauen wir uns die Verteilung einmal an, wenn wir die typischen Füllwörter entfernen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de38dea",
      "metadata": {
        "id": "6de38dea"
      },
      "outputs": [],
      "source": [
        "pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
        "text_corpus_without_stopwords = pattern.sub('', text_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834b57e5",
      "metadata": {
        "id": "834b57e5"
      },
      "source": [
        "Wir erzeugen die gleiche Visualisierung:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7373077",
      "metadata": {
        "id": "c7373077"
      },
      "outputs": [],
      "source": [
        "plot_most_common_words(text_corpus_without_stopwords, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22d694c",
      "metadata": {
        "id": "e22d694c"
      },
      "source": [
        "Wir können schon deutlich erkennen, dass es sich um einen Datenbestand zu Filmbewertungen handelt. Wir können uns das auch als Wordcloud (\"Wortwolke\") anschauen. Wir schreiben uns hierfür eine Funktion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48bb7bc",
      "metadata": {
        "id": "e48bb7bc"
      },
      "outputs": [],
      "source": [
        "def draw_word_cloud(text_corpus):\n",
        "    word_cloud = WordCloud(\n",
        "        collocations = False, background_color = 'white'\n",
        "    ).generate(text_corpus)\n",
        "    plt.imshow(word_cloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5841c94",
      "metadata": {
        "id": "b5841c94"
      },
      "source": [
        "Damit können wir die Worthäufigkeiten als Wordcloud darstellen lassen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c26c59",
      "metadata": {
        "id": "54c26c59",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "draw_word_cloud(text_corpus_without_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c43aa9cc",
      "metadata": {
        "id": "c43aa9cc"
      },
      "source": [
        "*Hinweis*:\n",
        "\n",
        "An sich liefert eine Wordcloud vom Informationsgehalt keinen Mehrwert gegenüber einer einfachen Darstellung anhand eines Scatter Plots. Tatsächlich ist es für uns sogar schwieriger zuzuordnen, welches Wort am häufigsten vorkommt (`movie` oder `film`?). Außerdem müssen wir häufig unsere Leserichtung anpassen. Vorteilhaft ist lediglich die platzsparende Art der Darstellung.\n",
        "\n",
        "Word Clouds werden gerne bei Textvisualisierungen verwendet - durchaus auch, weil es schlichtweg \"gut\" aussieht. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aed5fdb",
      "metadata": {
        "id": "9aed5fdb"
      },
      "source": [
        "Wir können uns diese Darstellung auch einmal je Klasse (\"positiv\" und \"negativ\") anzeigen; vielleicht erkennen wir klassenspezifische Wörter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1edbad0",
      "metadata": {
        "id": "f1edbad0"
      },
      "outputs": [],
      "source": [
        "positive_corpus = \" \".join(analysis_df[\"text\"].loc[analysis_df[\"label\"] == 1])\n",
        "negative_corpus = \" \".join(analysis_df[\"text\"].loc[analysis_df[\"label\"] == 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "277d32e0",
      "metadata": {
        "id": "277d32e0"
      },
      "source": [
        "Schauen wir uns zunächst die positiven Filmbewertungen in einer Wordcloud an:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a58f6f1",
      "metadata": {
        "id": "9a58f6f1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "draw_word_cloud(positive_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e081e7f",
      "metadata": {
        "id": "9e081e7f"
      },
      "source": [
        "Und anschließend die negativen Bewertungen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8a13dd9",
      "metadata": {
        "id": "f8a13dd9"
      },
      "outputs": [],
      "source": [
        "draw_word_cloud(negative_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7513af5d",
      "metadata": {
        "id": "7513af5d"
      },
      "source": [
        "Wir stellen fest, dass es Wörter gibt, die wir intuitiv vielleicht einer Klasse zugeordnet hätten (`good` -> positiv), aber auch in der gegenteiligen Klasse auftreten. Entstehen können solche Szenarien dann, wenn Wörter im Kontext des Satzes ihre Bedeutung ändern: `This film was really good.` vs. `In my opinion, this movie was not good at all.`\n",
        "\n",
        "Wir könnten hier noch tiefer in eine Analyse gehen und versuchen, mehr über unsere Daten zu verstehen (z.B. wie oft treten verneinte Sätze auf? Was sind klassentrennde Wörter?). An dieser Stelle werden wir aber für dieses Projekt die explorative Analyse beenden und mit der KI-Pipeline beginnen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6319500c",
      "metadata": {
        "id": "6319500c"
      },
      "source": [
        "# 3.5 Sentiment Analyse\n",
        "\n",
        "<img width=70% src=\"https://raw.githubusercontent.com/christianwarmuth/openhpi-kipraxis/main/images/cover_sentiment.jpeg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab6c366",
      "metadata": {
        "id": "dab6c366"
      },
      "source": [
        "### Lemmatisierung\n",
        "\n",
        "Wir können unsere Texte nun so anpassen, dass wir Wörter auf ihren Wortstamm reduzieren. Dafür eignet sich die Lemmatisierung."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28da649f",
      "metadata": {
        "id": "28da649f"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\n",
        "    \"lemmatization is the process of grouping together the inflected forms of a word.\"\n",
        ")\n",
        "for token in doc:\n",
        "    print(token, token.lemma_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ab923f",
      "metadata": {
        "id": "05ab923f"
      },
      "source": [
        "Wir bauen uns hier wieder eine Funktion für:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871c99c2",
      "metadata": {
        "id": "871c99c2"
      },
      "outputs": [],
      "source": [
        "def enrich_lemmatized_text(df):\n",
        "    df = df.copy()\n",
        "    df[\"lemmatized_text\"] = df[\"text\"].apply(\n",
        "        lambda x: \" \".join([token.lemma_ for token in nlp(x)])\n",
        "    )\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2539b731",
      "metadata": {
        "id": "2539b731"
      },
      "source": [
        "Und wenden diese anschließend auf unseren DataFrames an:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a8bb2e3",
      "metadata": {
        "id": "7a8bb2e3"
      },
      "outputs": [],
      "source": [
        "train_df = enrich_lemmatized_text(train_df)\n",
        "valid_df = enrich_lemmatized_text(valid_df)\n",
        "test_df = enrich_lemmatized_text(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93cb6756",
      "metadata": {
        "id": "93cb6756"
      },
      "source": [
        "Nun können wir mit der Tf-Idf Vektorisierung beginnen, welche unsere Texte in ein numerisches Format umwandelt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef97b86",
      "metadata": {
        "id": "8ef97b86"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "train_X = vectorizer.fit_transform(train_df[\"lemmatized_text\"]).astype(np.float32)\n",
        "valid_X = vectorizer.transform(valid_df[\"lemmatized_text\"]).astype(np.float32)\n",
        "test_X = vectorizer.transform(test_df[\"lemmatized_text\"]).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14469909",
      "metadata": {
        "id": "14469909"
      },
      "source": [
        "Unsere Daten sind vorbereitet, wir können mit dem Bau unserer KI-Modelle beginnen. Wir trainieren:\n",
        "- einen Entscheidungsbaum\n",
        "- einen Random Forest\n",
        "- eine logistische Regression\n",
        "- ein künstliches neuronales Netzwerk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46bb149",
      "metadata": {
        "id": "c46bb149"
      },
      "source": [
        "### Decision Tree (Entscheidungsbaum)\n",
        "\n",
        "Ein Entscheidungsbaum ist als sehr einfaches Modell und wird oft als eines der ersten Modelle verwendet. Wir trainieren und geben verschiedene Optionen für die Hyperparameter `max_depth` und `min_samples_split`. Die Hyperparameter-Suche GridSearch wählt hierbei die optimalen Hyperparameter aus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c6b53a",
      "metadata": {
        "id": "85c6b53a"
      },
      "outputs": [],
      "source": [
        "tree_clf = DecisionTreeClassifier()\n",
        "tree_params = {\n",
        "    'max_depth': list(range(10, 101, 20)) + [None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "tree_search = GridSearchCV(tree_clf, tree_params)\n",
        "tree_search.fit(train_X, train_df[\"label\"])\n",
        "best_tree_clf = tree_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d51906",
      "metadata": {
        "id": "39d51906"
      },
      "source": [
        "Anschließend wollen wir unser Modell auf den Validierungsdaten prüfen. Da wir das wiederholt machen werden, bauen wir wieder eine Hilfsfunktion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b066f025",
      "metadata": {
        "id": "b066f025"
      },
      "outputs": [],
      "source": [
        "def evaluate_clf(valid_X, labels, clf):\n",
        "    predictions = clf.predict(valid_X)\n",
        "    report = classification_report(labels, predictions)\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c068e7",
      "metadata": {
        "id": "c1c068e7"
      },
      "source": [
        "Anschließend führen wir diese aus und können die Ergebnisse prüfen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c4c076f",
      "metadata": {
        "id": "7c4c076f"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(valid_X, valid_df[\"label\"], best_tree_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04eb9d9c",
      "metadata": {
        "id": "04eb9d9c"
      },
      "source": [
        "### Random Forest\n",
        "\n",
        "Als nächstes Modell eignet sich ein Random Forest, welcher eine Ensemble-Technik darstellt. Im Wesentlichen werden hier mehrere Entscheidungsbäume trainiert, und deren Ergebnis vereint. Wir haben zusätzlich zu den vorherigen Hyperparametern noch `n_estimators` zu wählen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "463d7adb",
      "metadata": {
        "id": "463d7adb"
      },
      "outputs": [],
      "source": [
        "forest_clf = RandomForestClassifier()\n",
        "forest_params = {\n",
        "    'n_estimators': list(range(10, 101, 20)),\n",
        "    'max_depth': list(range(10, 101, 20)) + [None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "forest_search = GridSearchCV(forest_clf, forest_params)\n",
        "forest_search.fit(train_X, train_df[\"label\"])\n",
        "best_forest_clf = forest_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5a7cbf",
      "metadata": {
        "id": "6c5a7cbf"
      },
      "source": [
        "Wir evaluieren wieder das Ergebnis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "898a09f3",
      "metadata": {
        "id": "898a09f3"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(valid_X, valid_df[\"label\"], best_forest_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddcc5443",
      "metadata": {
        "id": "ddcc5443"
      },
      "source": [
        "### Logistic Regression\n",
        "\n",
        "Nun bauen wir eine logistische Regression. Diese ist ebenfalls sehr simpel, erweist sich oftmals aber als sehr gutes Modell. Wir haben vier Hyperparameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f27c9d5f",
      "metadata": {
        "id": "f27c9d5f"
      },
      "outputs": [],
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_params = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'max_iter': [100],\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "lr_search = GridSearchCV(lr_clf, lr_params)\n",
        "lr_search.fit(train_X, train_df[\"label\"])\n",
        "best_lr_clf = lr_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e9810a2",
      "metadata": {
        "id": "5e9810a2"
      },
      "source": [
        "Und wir evaluieren erneut:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e28ca6",
      "metadata": {
        "id": "c6e28ca6"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(valid_X, valid_df[\"label\"], best_lr_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7daa2369",
      "metadata": {
        "id": "7daa2369"
      },
      "source": [
        "### Feedforward Neural Network\n",
        "\n",
        "Zuletzt wollen wir noch ein künstliches neuronales Netz bauen. Dafür haben wir eine Architektur in der Datei `ffnn.py` gewählt, welche wir zuvor importiert haben und nun mit der Bibliothek skorch einfach anwenden können. Wir wählen hier direkt die Hyperparameter ohne GridSearch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae567816",
      "metadata": {
        "id": "ae567816",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "neural_net = NeuralNetClassifier(\n",
        "    module=NeuralNetModule,\n",
        "    module__num_inputs = len(vectorizer.vocabulary_),\n",
        "    max_epochs=10,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    iterator_train__shuffle=True,\n",
        "    verbose=0\n",
        ")\n",
        "neural_net.fit(train_X, train_df['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd74db8a",
      "metadata": {
        "id": "bd74db8a"
      },
      "source": [
        "Nun prüfen wir das Ergebnis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2b9399",
      "metadata": {
        "id": "fc2b9399"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(valid_X, valid_df[\"label\"], neural_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f6528ca",
      "metadata": {
        "id": "3f6528ca"
      },
      "source": [
        "Unser bestes Modell auf den Validierungsdaten ist die logistische Regression, daher wählen wir diese als unser finales Modell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6ae2ef2",
      "metadata": {
        "id": "f6ae2ef2"
      },
      "source": [
        "### Test unseres Modells\n",
        "\n",
        "Wir haben die Validierungsdaten gewählt, um unser bestes Modell auszuwählen. Es kann aber sein, dass unser Modell auf den Validierungsdaten nur zufällig gute Prognosen erzeugt hatte oder wir uns zu sehr durch die Hyperparameter-Optimierung auf unser Validierungs-Daten \"überangepasst\" haben. Daher evaluieren wir auf einem noch vollkommen \"neuen\" Teil der Daten, unseren Testdaten:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38bda81f",
      "metadata": {
        "id": "38bda81f"
      },
      "outputs": [],
      "source": [
        "evaluate_clf(test_X, test_df[\"label\"], best_lr_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0af480c9",
      "metadata": {
        "id": "0af480c9"
      },
      "source": [
        "Die Ergebnisse sind sogar tatsächlich etwas besser, als auf unseren Validierungsdaten.\n",
        "\n",
        "Wir könnten an dieser Stelle noch zahlreiche weitere Untersuchungen machen. Wir könnten beispielsweise untersuchen, ob es Unterschiede in der Prognosequalität abhängig von der Textlänge gibt, oder ob unser Modell Verneinungen erkennt und korrekt interpretiert. Für dieses Projekt belassen wir es aber bei den Ergebnissen."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "3.5 Sentiment Analyse.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
